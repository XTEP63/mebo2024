{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3. Previas conjugadas\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://storage.needpix.com/rsynced_images/bayesian-2889576_1280.png\" width=\"200px\" height=\"180px\" />\n",
    "\n",
    "En esta tercera tarea, reforzaremos el cálculo de distribuciones posteriores usando previas conjugadas.\n",
    "\n",
    "Por favor, intenta ser lo más explícit@ posible, y en lo posible, apóyate de la escritura matemática con $\\LaTeX$.\n",
    "\n",
    "Recuerda además que ante cualquier duda, me puedes contactar al correo esjimenezro@iteso.mx.\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://storage.needpix.com/rsynced_images/bayesian-2889576_1280.png.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Beta es previa conjugada de Bernoulli\n",
    "\n",
    "Completar la siguiente tabla de actualización:\n",
    "\n",
    "| Hipótesis | Datos | Previa                                         | Verosimilitud               | Posterior                                               |\n",
    "| --------- | ----- | ---------------------------------------------- | --------------------------- | ------------------------------------------------------- |\n",
    "| $\\theta$  | $x$   | $\\text{Beta}(a, b)$                            | $\\text{Bernoulli}(\\theta)$  | ?                                                       |\n",
    "| $\\theta$  | $x=1$ | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x\\|\\theta)=\\theta$       | ?                                                       |\n",
    "| $\\theta$  | $x=0$ | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x\\|\\theta)=(1 - \\theta)$ | ?                                                       |\n",
    "\n",
    "Si se tienen constantes en la tabla, como por ejemplo $c_1$, especificarlas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Beta es previa conjugada de Bernoulli\n",
    "\n",
    "\n",
    "| Hipótesis | Datos | Previa                                         | Verosimilitud               | Posterior                                               |\n",
    "| --------- | ----- | ---------------------------------------------- | --------------------------- | ------------------------------------------------------- |\n",
    "| $\\theta$  | $x$   | $\\text{Beta}(a, b)$                            | $\\text{Bernoulli}(\\theta)$  | $\\text{Beta}(a + x, b + 1 - x)$                        |\n",
    "| $\\theta$  | $x=1$ | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x \\mid \\theta)=\\theta$       | $p(\\theta \\mid x=1) = c_2\\theta^{a}(1-\\theta)^{b-1}$   |\n",
    "| $\\theta$  | $x=0$ | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x \\mid \\theta)=(1 - \\theta)$ | $p(\\theta \\mid x=0) = c_3\\theta^{a-1}(1-\\theta)^{b}$   |\n",
    "\n",
    "Aquí, al igual que en el caso de Bernoulli, las constantes $c_1$ y $c_2$ normalizan la distribución. Se observa que la posterior sigue una distribución Beta con parámetros actualizados dependiendo de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beta es previa conjugada de geométrica\n",
    "\n",
    "Completar la siguiente tabla de actualización:\n",
    "\n",
    "| Hipótesis | Datos | Previa                                         | Verosimilitud                     | Posterior                                               |\n",
    "| --------- | ----- | ---------------------------------------------- | --------------------------------- | ------------------------------------------------------- |\n",
    "| $\\theta$  | $x$   | $\\text{Beta}(a, b)$                            | $\\text{Geometrica}(\\theta)$       | ?                                                       |\n",
    "| $\\theta$  | $x$   | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x\\|\\theta)=\\theta(1-\\theta)^x$ | ?                                                       |\n",
    "\n",
    "Si se tienen constantes en la tabla, como por ejemplo $c_1$, especificarlas completamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hipótesis | Datos | Previa                                         | Verosimilitud                     | Posterior                                               |\n",
    "| --------- | ----- | ---------------------------------------------- | --------------------------------- | ------------------------------------------------------- |\n",
    "| $\\theta$  | $x$   | $\\text{Beta}(a, b)$                            | $\\text{Geometrica}(\\theta)$       | $\\text{Beta}(a + 1, b + x)$                             |\n",
    "| $\\theta$  | $x$   | $p(\\theta)=c_1\\theta^{a-1} (1 - \\theta)^{b-1}$ | $p(x \\mid \\theta)=\\theta(1-\\theta)^x$ | $p(\\theta \\mid x) = c_2 \\theta^{a}(1-\\theta)^{b+x}$   |\n",
    "\n",
    "Los factores de normalización $c_1$ y $c_2$ son constantes que se determinan para garantizar que las distribuciones sean válidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gamma es previa conjugada de Poisson\n",
    "\n",
    "Supongamos que tenemos un dato $x \\in \\mathbb{N}$ que tiene una verosimilitud de $\\text{Poisson}(\\theta)$:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) = \\frac{\\theta^x e^{-\\theta}}{x!}.\n",
    "$$\n",
    "\n",
    "Ahora, si elegimos la distribución previa sobre el parámetro $\\theta$ como una distribución $\\text{Gamma}(a, b)$:\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} \\exp\\{-b \\theta\\}\n",
    "$$\n",
    "\n",
    "Encontrar completamente la densidad de probabilidad posterior\n",
    "\n",
    "$$\n",
    "p(\\theta | x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gamma es previa conjugada de Poisson\n",
    "\n",
    "Supongamos que tenemos un dato $x \\in \\mathbb{N}$ que tiene una verosimilitud de $\\text{Poisson}(\\theta)$:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) = \\frac{\\theta^x e^{-\\theta}}{x!}.\n",
    "$$\n",
    "\n",
    "Ahora, si elegimos la distribución previa sobre el parámetro $\\theta$ como una distribución $\\text{Gamma}(a, b)$:\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} \\exp\\{-b \\theta\\}\n",
    "$$\n",
    "\n",
    "Encontrar completamente la densidad de probabilidad posterior\n",
    "\n",
    "$$\n",
    "p(\\theta | x)\n",
    "$$\n",
    "\n",
    "1. **Verosimilitud**: La verosimilitud de $x$ dado $\\theta$ es:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) = \\frac{\\theta^x e^{-\\theta}}{x!}\n",
    "$$\n",
    "\n",
    "2. **Distribución previa**: La distribución previa sobre $\\theta$ es:\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} \\exp\\{-b \\theta\\}\n",
    "$$\n",
    "\n",
    "3. **Multiplicando la verosimilitud por la previa**:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) p(\\theta) = \\left( \\frac{\\theta^x e^{-\\theta}}{x!} \\right) \\left( \\frac{b^a}{\\Gamma(a)} \\theta^{a - 1} e^{-b \\theta} \\right)\n",
    "$$\n",
    "\n",
    "Esto se simplifica a:\n",
    "\n",
    "$$\n",
    "= \\frac{b^a}{\\Gamma(a)} \\frac{1}{x!} \\theta^{x + a - 1} e^{-(1 + b) \\theta}\n",
    "$$\n",
    "\n",
    "4. **Densidad marginal** $p(x)$: La densidad marginal $p(x)$ se puede considerar como una constante respecto a $\\theta$ cuando se está calculando la posterior, así que la ignoramos en este paso.\n",
    "\n",
    "5. **Densidad posterior**: La densidad posterior se obtiene normalizando el producto anterior:\n",
    "\n",
    "$$\n",
    "p(\\theta | x) \\propto \\theta^{x + a - 1} e^{-(1 + b) \\theta}\n",
    "$$\n",
    "\n",
    "Esta forma se puede identificar como una distribución Gamma:\n",
    "\n",
    "$$\n",
    "p(\\theta | x) \\sim \\text{Gamma}(a + x, b + 1)\n",
    "$$\n",
    "\n",
    "Finalmente, la densidad de probabilidad posterior se puede expresar como:\n",
    "\n",
    "$$\n",
    "p(\\theta | x) = \\frac{(b + 1)^{a + x}}{\\Gamma(a + x)} \\theta^{a + x - 1} e^{-(b + 1) \\theta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fórmulas de actualización normal\n",
    "\n",
    "Supongamos que tenemos un dato $x \\sim \\text{Normal}(\\theta, \\sigma^2)$, donde la varianza $\\sigma^2$ es conocida. Es decir, la media $\\theta$ es nuestro parámetro deconocido de interés. Si elegimos una previa normal\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Normal}(\\mu_0, \\sigma_0^2),\n",
    "$$\n",
    "\n",
    "entonces la posterior también es normal $(\\theta | x) \\sim \\text{Normal}(\\mu_1, \\sigma_1^2)$. Demostrar que\n",
    "\n",
    "$$\n",
    "\\frac{\\mu_1}{\\sigma_1^2} = \\frac{\\mu_0}{\\sigma_1^2} + \\frac{x}{\\sigma^2}, \\qquad \\frac{1}{\\sigma_1^2} = \\frac{1}{\\sigma_0^2} + \\frac{1}{\\sigma^2},\n",
    "$$\n",
    "\n",
    "o equivalentemente\n",
    "\n",
    "$$\n",
    "\\mu_1 = \\frac{\\mu_0 / \\sigma_0^2 + x / \\sigma^2}{1 / \\sigma_0^2 + 1 / \\sigma^2} = \\frac{\\sigma^2 \\mu_0 + \\sigma_0^2 x}{\\sigma_0^2 + \\sigma^2}, \\qquad \\sigma_1^2 = \\frac{1}{1 / \\sigma_0^2 + 1 / \\sigma^2} = \\frac{\\sigma_0^2\\sigma^2}{\\sigma_0^2 + \\sigma^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fórmulas de actualización normal\n",
    "\n",
    "Supongamos que tenemos un dato $x \\sim \\text{Normal}(\\theta, \\sigma^2)$, donde la varianza $\\sigma^2$ es conocida. Es decir, la media $\\theta$ es nuestro parámetro desconocido de interés. Si elegimos una previa normal\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Normal}(\\mu_0, \\sigma_0^2),\n",
    "$$\n",
    "\n",
    "entonces la posterior también es normal $(\\theta | x) \\sim \\text{Normal}(\\mu_1, \\sigma_1^2)$. Demostrar que\n",
    "\n",
    "$$\n",
    "\\frac{\\mu_1}{\\sigma_1^2} = \\frac{\\mu_0}{\\sigma_0^2} + \\frac{x}{\\sigma^2}, \\qquad \\frac{1}{\\sigma_1^2} = \\frac{1}{\\sigma_0^2} + \\frac{1}{\\sigma^2},\n",
    "$$\n",
    "\n",
    "o equivalentemente\n",
    "\n",
    "$$\n",
    "\\mu_1 = \\frac{\\mu_0 / \\sigma_0^2 + x / \\sigma^2}{1 / \\sigma_0^2 + 1 / \\sigma^2} = \\frac{\\sigma^2 \\mu_0 + \\sigma_0^2 x}{\\sigma_0^2 + \\sigma^2}, \\qquad \\sigma_1^2 = \\frac{1}{1 / \\sigma_0^2 + 1 / \\sigma^2} = \\frac{\\sigma_0^2\\sigma^2}{\\sigma_0^2 + \\sigma^2}\n",
    "$$\n",
    "\n",
    "### Demostración\n",
    "\n",
    "1. **Verosimilitud**: La verosimilitud de $x$ dado $\\theta$ es:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) \\propto \\exp\\left\\{ -\\frac{(x - \\theta)^2}{2\\sigma^2} \\right\\}\n",
    "$$\n",
    "\n",
    "2. **Distribución previa**: La previa de $\\theta$ es:\n",
    "\n",
    "$$\n",
    "p(\\theta) \\propto \\exp\\left\\{ -\\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2} \\right\\}\n",
    "$$\n",
    "\n",
    "3. **Distribución posterior**: La posterior se obtiene multiplicando la verosimilitud por la previa:\n",
    "\n",
    "$$\n",
    "p(\\theta | x) \\propto \\exp\\left\\{ -\\frac{(x - \\theta)^2}{2\\sigma^2} \\right\\} \\exp\\left\\{ -\\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2} \\right\\}\n",
    "$$\n",
    "\n",
    "Combinando los exponentes:\n",
    "\n",
    "$$\n",
    "-\\frac{(x - \\theta)^2}{2\\sigma^2} - \\frac{(\\theta - \\mu_0)^2}{2\\sigma_0^2}\n",
    "$$\n",
    "\n",
    "Expandimos ambos términos:\n",
    "\n",
    "$$\n",
    "-\\frac{x^2 - 2x\\theta + \\theta^2}{2\\sigma^2} - \\frac{\\theta^2 - 2\\mu_0\\theta + \\mu_0^2}{2\\sigma_0^2}\n",
    "$$\n",
    "\n",
    "Agrupamos los términos que dependen de $\\theta$:\n",
    "\n",
    "$$\n",
    "-\\left( \\frac{1}{2\\sigma^2} + \\frac{1}{2\\sigma_0^2} \\right)\\theta^2 + \\left( \\frac{x}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2} \\right)\\theta\n",
    "$$\n",
    "\n",
    "Esto tiene la forma cuadrática de una distribución normal. El coeficiente de $\\theta^2$ determina $\\sigma_1^2$ y el coeficiente lineal de $\\theta$ determina $\\mu_1$. \n",
    "\n",
    "4. **Cálculo de $\\sigma_1^2$**:\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sigma_1^2} = \\frac{1}{\\sigma^2} + \\frac{1}{\\sigma_0^2}\n",
    "$$\n",
    "\n",
    "5. **Cálculo de $\\mu_1$**:\n",
    "\n",
    "$$\n",
    "\\mu_1 = \\frac{\\frac{x}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\sigma_0^2}} = \\frac{\\sigma^2 \\mu_0 + \\sigma_0^2 x}{\\sigma_0^2 + \\sigma^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
